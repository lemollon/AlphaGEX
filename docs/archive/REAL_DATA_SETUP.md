# Real Data Collection Setup Guide

## Current Status

Your AlphaGEX system is configured but **needs API keys** to collect real market data.

**What's Working:**
- ✅ Database initialized and ready
- ✅ All collectors scripts created
- ✅ Automated scheduler configured (runs every 5-10 minutes)
- ✅ Beautiful empty state UI with progress tracking

**What's Needed:**
- ❌ Trading Volatility API key (for GEX data)
- ❌ API configuration in .env file

---

## Quick Start: Enable Real Data Collection

### Step 1: Get API Access

You need a **Trading Volatility API key** to collect real GEX data:

1. Go to: https://tradingvolatility.net
2. Sign up for an account
3. Get your API key from account settings

**Alternative:** If you have options data from another source (Polygon, TastyTrade, etc.), you can integrate it by modifying `gex_history_snapshot_job.py`

### Step 2: Configure Environment

Create `/home/user/AlphaGEX/.env` file:

```bash
cd /home/user/AlphaGEX
cp .env.template .env
```

Edit `.env` and add your API key:

```bash
# Required for real GEX data
TRADING_VOLATILITY_API_KEY=your_actual_api_key_here

# Optional - for AI features
ANTHROPIC_API_KEY=your_claude_api_key_here
```

### Step 3: Start Data Collection

**Option A: Automated Collection (Recommended)**

Runs every 5-10 minutes during market hours:

```bash
cd /home/user/AlphaGEX
./manage_collector.sh start
```

Check status:
```bash
./manage_collector.sh status
./manage_collector.sh logs
```

**Option B: Manual Collection (Testing)**

Run once to test:

```bash
cd /home/user/AlphaGEX
python3 -c "
from gex_history_snapshot_job import save_gex_snapshot
save_gex_snapshot('SPY')
"
```

---

## Data Collection Schedule

Once configured, here's what runs automatically:

| Collector | Frequency | What It Does |
|-----------|-----------|--------------|
| **GEX History** | Every 5 min | Saves GEX snapshots, flip points, gamma walls |
| **Forward Magnets** | Every 5 min | Detects strikes acting as price magnets |
| **Liberation Outcomes** | Every 10 min | Tracks psychology trap prediction accuracy |
| **Gamma Expiration** | Every 30 min | Monitors gamma changes by DTE |
| **Daily Performance** | 4:00 PM ET | Calculates daily P&L and metrics |

**Market Hours:** 9:30 AM - 4:00 PM ET (Monday-Friday)

**Immediate Historical Data Access:**
Instead of waiting 30+ days for data to accumulate, you can backfill historical data immediately:

```bash
# Backfill 1 year of historical data from Polygon
python backfill_historical_data.py --days 365

# Backfill specific symbol
python backfill_historical_data.py --symbol SPY --days 180
```

This populates your database with historical GEX, gamma, and psychology signals instantly, giving you immediate access to charts and analytics.

---

## What Pages Will Show

### Psychology Performance Tracker
- **Requires:** `regime_signals` data from psychology trap analysis
- **Generated by:** Running psychology trap detector on `/psychology` page
- **Frequency:** Real-time when you analyze market conditions

### GEX History
- **Requires:** TradingVolatility API or options data
- **Generated by:** `gex_history_snapshot_job.py`
- **Frequency:** Every 5 minutes (72-80 data points per day)

### Probability Dashboard
- **Requires:** Multiple data sources + outcomes validation
- **Generated by:** System predictions + outcome tracking
- **Frequency:** Accumulates over weeks

### Recommendations History
- **Requires:** AI trade recommendations
- **Generated by:** AI Copilot generating trade ideas
- **Frequency:** 1-5 recommendations per day

---

## Troubleshooting

### "No GEX data sources available"
- Check `.env` file has `TRADING_VOLATILITY_API_KEY`
- Verify API key is valid (test on tradingvolatility.net)
- Check logs: `./manage_collector.sh logs`

### "Market closed"
- Normal! Collections only run during market hours (9:30 AM - 4:00 PM ET, Mon-Fri)
- Data collectors will auto-resume when market opens

### No data in database
- Run manually to test: `python3 gex_history_snapshot_job.py`
- Check if market is open (collections only during market hours)
- Verify API connectivity

### Want to test without API?
- The UI will show beautiful empty states with progress tracking
- You'll see "Configure API keys to begin data collection"
- Once configured, real data will populate automatically

---

## Development / Testing Mode

If you want to develop/test the UI without waiting for real data:

```bash
cd /home/user/AlphaGEX/backend

# Generate test data (marked as PLACEHOLDER)
python3 generate_placeholder_data.py

# Clear test data later
python3 -c "
import sqlite3
conn = sqlite3.connect('gex_copilot.db')
c = conn.cursor()
c.execute('DELETE FROM gex_history WHERE data_source = \"HISTORICAL_PLACEHOLDER\"')
conn.commit()
"
```

**Note:** Placeholder data is clearly marked so you know it's not real.

---

## Next Steps

1. **Get API key** from Trading Volatility
2. **Configure `.env`** with your API key
3. **Start collector:** `./manage_collector.sh start`
4. **Watch it accumulate:** Check pages every few hours to see progress
5. **Monitor status:** `./manage_collector.sh logs`

Within 24 hours, you'll have real data showing trends!

---

## Questions?

- Check logs: `tail -f /var/log/alphagex-collector.log`
- Test individual collectors: `python3 gex_history_snapshot_job.py`
- Verify database: `sqlite3 backend/gex_copilot.db "SELECT COUNT(*) FROM gex_history"`
